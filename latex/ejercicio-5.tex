\textit{Diseñar e implementar un algoritmo para CIDM que use la metaheurística GRASP.}

\subsection{Ejercicio A}

\textit{Explicar detalladamente el algoritmo implementado. Plantear distintos criterios de parada y de selección de la lista de candidatos (RCL) de la heurística golosa aleatorizada.}

\medskip

\subsubsection{Idea general}

Como pide el enunciado, la idea general del algoritmo es usar la metaheurística GRASP, para lo cual es necesario tener implementaciones de: heurística constructiva golosa y heurística de búsqueda local, que fueron conveniemente implementadas en los puntos anteriores.

La estructura general de un algoritmo GRASP es:

\begin{codesnippet}
1. Poner en mejor_solucion una primera solucion Random.
2. Mientras no se cumpla el criterio de parada hacer:
3.     Poner en nueva_solucion una solucion usando la funcion ConstruirGreedyRandom()
4.     Intentar mejorar la nueva_solucion usando la funcion BusquedaLocal()
5.     Si costo(nueva_solucion) < costo(mejor_solucion) hacer:
6.         Poner en mejor_solucion la nueva_solucion
\end{codesnippet}

En nuestro algoritmo se implementó de la siguiente forma:
\begin{enumerate}
    \item Se utilizo para la primera 'mejor_solución' Random el mismo método ConstruirGreedyRandom que se utiliza al generar una solución golosa randomizada.
    \item Los criterios de parada considerados se detallan más adelante.
    \item La función ConstruirGreedyRandom es una variación del algoritmo goloso implementado para el Ejercicio 3 (agregando lista de candidatos), detallado más adelante.
    \item La función BusquedaLocal es identica al algoritmo implementado para el Ejercicio 4. En la experimentación se probo con los criterios de vecindad 1 y 2 expuestos en ese mismo Ejercicio.
    \item Definimos el costo de una solución como la cantidad de nodos de dicha solución, por lo que decimos que una es mejor que otra si la primera tiene menor cantidad de nodos.
    \item Si encontramos una solución con menor cantidad de nodos que la mejor hasta ese momento, la guardamos como mejor solución.
\end{enumerate}

\subsubsection{Criterios de parada}
Los criterios de parada que se utilizaron para la implementación se pensaron en función de la cantidad de nodos del grafo original:
\begin{enumerate}
    \item Criterio 1: realizar $n$ iteraciones, con $n$ la cantidad de nodos del grafo.
    \item Criterio 2: sea k una constante, seguir iterando hasta que la mejor solucion parcial no se mejore durante k ciclos seguidos.
\end{enumerate}

\subsubsection{Selección de lista de candidatos (RCL)}
Al algoritmo con heurística constructiva golosa del Ejercicio 3 se lo modificó de la siguiente forma:
\begin{itemize}
    \item En vez de iterar en los elementos del array de nodos ordenados por grado, iteramos hasta que hayamos visitado $n$ nodos usando un contador, ya que no necesariamente vamos a visitar secuencialmente todos los nodos desde el índice 0 hasta el (n-1)-ésimo.
    \item Dentro del ciclo principial, lo primero que hacemos es elegir el indice de un nodo para agregar a la solución.

    A diferencia del algoritmo goloso original, que elegiamos siempre el nodo con grado más alto no visitado hasta ese momento, ahora vamos a tener una lista de candidatos (nodos) a agregar a la solución, y de todos ellos vamos a elegir alguno de manera aleatoria.

    La lista de candidatos se construye de dos formas posibles:
    \begin{enumerate}
        \item Criterio 1: tomando como referencia el nodo con grado más alto no visitado hasta ese momento. Si $d_{max}$ es dicho grado, agregaremos a la lista de candidatos todos los nodos que tengan grado al menos $\alpha$ * $d_{max}$ ($\alpha$ constante). Es decir, sea $d$ el grado del nodo, los consideramos si $d \geq d{max} * \alpha$. Donde $\alpha$ es un valor entre 0 y 1.
        \item Criterio 2: en vez de tomar como referencia el grado de mayor elemento, simplemente tomamos los k elementos de mayor grado no visitados hasta el momento, con k un valor constante entero.
    \end{enumerate}

    Esto nos asegura que, si bien el nodo a agregar a la solución es aleatorio, se encuentra dentro de cierto grupo de nodos mejores que otros.

    \item Luego de que se eligió un nodo, se lo agrega a la solución, y luego se lo borra de los nodos posibles para futuras iteraciones (se lo marca como \textit{visitado}). Además, se aumenta en uno la cantidad de nodos visitados.
    \item Por último, se itera sobre todos los nodos adyacentes al elegido, borrandolos de los nodos posibles y aumentando en uno el contador de nodos visitados.
\end{itemize}

\subsubsection{Pseudocódigo}

El esquema general del algoritmo GRASP ya se mostró en la sección Idea General, y el algoritmo de Busqueda Local es identico al utilizado en el Ejercicio 4, por lo que mostraremos aquí solo el pseudocódigo de la función ConstruirGreedyRandom (con el primer criterio de lista de candidatos, el segundo simplemente elige los k nodos de mayor grado, con k una constante):

\begin{codesnippet}
Poner nodos = un vector de structs Nodo, que tiene el indice del nodo y su grado
    en el grafo, de tamaño n.
Ordenar dicho conjunto de mayor a menor grado.
Poner solucion = un vector de enteros inicializados en 0. El valor en cada indice
    representa si el nodo con dicho indice pertenece o no a la solución.
Poner nodos_visitados = 0
Mientras nodos_visitados < n hacer:
    Poner mejor_grado = nodos[0].grado
    Poner limite_indice = 0
    Para i desde 0 hasta |nodos| hacer:
        Si nodos[i].grado >= mejor_grado - mejor_grado * alpha hacer:
            limite_indice = i
        Sino
            Salir ciclo Para
        Fin Si
    Fin Para

    Poner indice_nuevo = random_in_range(0, min(limite_indice, |nodos|-1))
    Poner nodo_nuevo = nodos[indice_nuevo].indice
    Agrego nodo_nuevo al vector solucion y lo borro del vector nodos
    Incrementar nodos_visitados en uno

    Para v en Adyacentes(nodo_nuevo) hacer:
        Si v esta en nodos hacer:
            Borrar v del vector nodos
            Incrementar nodos_visitados en uno
        Fin Si
    Fin Para
Fin Mientras
Devolver solucion
\end{codesnippet}

\subsection{Ejercicio B}

\textit{Realizar una experimentación que permita observar los tiempos de ejecución y la calidad de las soluciones obtenidas.}

\medskip

Consideraciones:

\begin{itemize}
    \item Todas las tomas de tiempos fueron hechas bajo las mismas condiciones (computadora, fuente de energia, minima cantidad de procesos abiertos).
    \item Varias muestras fueron tomadas de cada dato para luego ser promediados y asi dar datos mas confiables.
    \item En base a lo explicado anteriormente, realizamos experimentos basando los criterios de los algoritmos para asi crear diferentes versiones del mismo.
    \item La diferencia entre ellas son los siguientes criterios:
    \begin{itemize}
        \item Criterio de parada 1: realizar $n$ iteraciones, con $n$ la cantidad de nodos del grafo.
        \item Criterio de parada 2: sea k una constante, seguir iterando hasta que la mejor solucion parcial no se mejore durante k ciclos seguidos.

        \item Criterio de lista de candidatos aleatoria 1: tomamos los nodos que tengan grado al menos $\alpha$ * $d_{max}$ ($\alpha$ constante) con $d_{max}$ el mayor de los grados entre los nodos no visitados.
        \item Criterio de lista de candidatos aleatoria 2: tomar los k elementos de mayor grado no visitados hasta el momento, con k un valor constante entero.

        \item Criterio de vecindad en búsqueda local 1: generar soluciones vecinas a partir de quitar k vértices que pertenecen al subconjunto CID de la solución inicial y agregar 1 vértice al subconjunto.
        \item Criterio de vecindad en búsqueda local 2: generar soluciones vecinas a partir de quitar k vértices que pertenecen al subconjunto CID de la solución inicial y agregar, hasta, k-1 vértices al subconjunto.
    \end{itemize}
    \item Las versiones sobre las cuales experimentamos fueron:
    \begin{itemize}
        \item v111: criterio parada 1, criterio lista candidatos 1, criterio búsqueda local 1.
        \item v112: criterio parada 1, criterio lista candidatos 1, criterio búsqueda local 2.
        \item v121: criterio parada 1, criterio lista candidatos 2, criterio búsqueda local 1.
        \item v122: criterio parada 1, criterio lista candidatos 2, criterio búsqueda local 2.
        \item v211: criterio parada 2, criterio lista candidatos 1, criterio búsqueda local 1.
        \item v212: criterio parada 2, criterio lista candidatos 1, criterio búsqueda local 2.
        \item v221: criterio parada 2, criterio lista candidatos 2, criterio búsqueda local 1.
        \item v222: criterio parada 2, criterio lista candidatos 2, criterio búsqueda local 2.
    \end{itemize}
    \item Cuando comparamos los tiempos de ejecución, el eje 'x' determina el tamaño de la entrada (que puede ser la cantidad de nodos, ejes del grafo o la suma de ellos). El eje 'y' representará el tiempo que tardo el algoritmo en nanosegundos.
    \item La toma de tiempos en nanosegundos se realiza con la libreria 'chrono' de C++.
    \item La aleatorización de algunas variables (por ejemplo, para elegir un candidato de la Lista Restringida de Candidatos RCL) se hizo con la función std::rand.
    \item Para la comparacion de calidad de resultados, tomamos como eje 'x' la cantidad de nodos del grafo, le agregamos aristas aleatoriamente y luego corremos el algoritmo con las diferentes versiones. El eje 'y' en este caso seria la cantidad de nodos del CIDM que devuelve la version del algoritmo. Finalmente promediamos los resultados para cada 'x'.

\end{itemize}

\subsubsection{Tiempos de ejecución}
